{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(data.no_stopwords)\n",
    "y = data.rating > data.rating.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, valX, trainy, valy = train_test_split(X, y, train_size=0.8, random_state=486)\n",
    "valX, testX, valy, testy = train_test_split(valX, valy, train_size=0.5, random_state=486)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MultinomialNB()\n",
    "clf.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8107606679035251"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(valy, clf.predict(valX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8278481012658228"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(valy, clf.predict(valX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9052555890407818"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(valy, clf.predict_proba(valX)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features with highest and lowest coefs\n",
    "\n",
    "It looks like most of the features with extreme coefficients are actually usernames. Let's try to filter those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'so', 'not', 'like', 'blue', 'win', 'we', 'composition',\n",
       "       'day', 'angle', 'perfect', 'game', 'back', 'lovely', 'chair',\n",
       "       'camera', 'it', 'pillows', 'view', 'more', 'strong', 'pineapple',\n",
       "       'color', 'new', 'one', 'work', 'lit', 'points', 'book', 'add',\n",
       "       'update', 'wall', 'skype', 'rooms', 'set', 'pillow', 'lamp',\n",
       "       'books', 'flowers', 'nice', 'up', 'light', 'lighting', 'good',\n",
       "       'depth', 'well', 'plant', 'great', 'love', 'art'], dtype='<U28')"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.argsort(clf.coef_)[0, -50:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kidnappers', 'relight', 'gwaynemiller', 'relieved', 'reliably',\n",
       "       'gwlichtenstein', 'gwtvcrossfire', 'religion', 'relevant',\n",
       "       'gymjordan', 'relevance', 'relegated', 'hackingdave', 'releases',\n",
       "       'hadasthier', 'relevancy', 'hades', 'guypratt', 'religious',\n",
       "       'gunnut', 'remembers', 'remedial', 'guru', 'gussy',\n",
       "       'remaxadamcontos', 'guylafleur', 'guston', 'remaining', 'guts',\n",
       "       'remainders', 'remainder', 'relocation', 'guyfieri', 'remake',\n",
       "       'hadinili', 'release', 'hagarchemali', 'halted', 'reign', 'ham',\n",
       "       'reidepstein', 'reichlinmelnick', 'hamilton_lane', 'reigns',\n",
       "       'hammer', 'rehang', 'hamper', 'hampshire', 'rehabilitation',\n",
       "       'hamster'], dtype='<U28')"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.argsort(clf.coef_)[0, :50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "at_re = re.compile(r\"@[\\w_]+\")\n",
    "def strip_ats(tweet):\n",
    "    return at_re.sub(\"\", tweet)\n",
    "\n",
    "hash_re = re.compile(r\"#\\w+\")\n",
    "def strip_hashtags(tweet):\n",
    "    return hash_re.sub(\"\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(data.cleaned.apply(strip_ats).apply(strip_hashtags))\n",
    "y = data.rating > data.rating.median()\n",
    "\n",
    "trainX, valX, trainy, valy = train_test_split(X, y, train_size=0.8, random_state=486)\n",
    "valX, testX, valy, testy = train_test_split(valX, valy, train_size=0.5, random_state=486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8107606679035251, 0.8278481012658228, 0.9052555890407818)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(trainX, trainy)\n",
    "f1_score(valy, clf.predict(valX)), accuracy_score(valy, clf.predict(valX)), roc_auc_score(valy, clf.predict_proba(valX)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['happy', 'so', 'not', 'like', 'blue', 'win', 'we', 'composition',\n",
       "       'day', 'angle', 'perfect', 'game', 'back', 'lovely', 'chair',\n",
       "       'camera', 'it', 'pillows', 'view', 'more', 'strong', 'pineapple',\n",
       "       'color', 'new', 'one', 'work', 'lit', 'points', 'book', 'add',\n",
       "       'update', 'wall', 'skype', 'rooms', 'set', 'pillow', 'lamp',\n",
       "       'books', 'flowers', 'nice', 'up', 'light', 'lighting', 'good',\n",
       "       'depth', 'well', 'plant', 'great', 'love', 'art'], dtype='<U28')"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.argsort(clf.coef_)[0, -50:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['kidnappers', 'relight', 'gwaynemiller', 'relieved', 'reliably',\n",
       "       'gwlichtenstein', 'gwtvcrossfire', 'religion', 'relevant',\n",
       "       'gymjordan', 'relevance', 'relegated', 'hackingdave', 'releases',\n",
       "       'hadasthier', 'relevancy', 'hades', 'guypratt', 'religious',\n",
       "       'gunnut', 'remembers', 'remedial', 'guru', 'gussy',\n",
       "       'remaxadamcontos', 'guylafleur', 'guston', 'remaining', 'guts',\n",
       "       'remainders', 'remainder', 'relocation', 'guyfieri', 'remake',\n",
       "       'hadinili', 'release', 'hagarchemali', 'halted', 'reign', 'ham',\n",
       "       'reidepstein', 'reichlinmelnick', 'hamilton_lane', 'reigns',\n",
       "       'hammer', 'rehang', 'hamper', 'hampshire', 'rehabilitation',\n",
       "       'hamster'], dtype='<U28')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.argsort(clf.coef_)[0, :50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([129., 192.,  99., 192., 192.,  99.,  99., 192., 192.,  99., 192.,\n",
       "       192.,  99., 192.,  99., 192.,  99.,  99., 192.,  99., 193., 193.,\n",
       "        99.,  99., 192.,  99.,  99., 192.,  99., 192., 192., 192.,  99.,\n",
       "       192.,  99., 192.,  99., 100., 192., 100., 192., 192., 100., 192.,\n",
       "       100., 192., 100., 100., 192., 100.])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(np.argsort(clf.coef_)[0, :50]/ np.argsort(clf.coef_)[0, 49] * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
