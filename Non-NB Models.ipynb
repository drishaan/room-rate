{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "established-trance",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dietary-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./data/cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "closing-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-groove",
   "metadata": {},
   "source": [
    "# Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "inappropriate-rugby",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "contained-rebate",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(data.cleaned)\n",
    "y = data.rating > data.rating.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "gothic-breakfast",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX, valX, trainy, valy = train_test_split(X, y, train_size=0.8, random_state=486)\n",
    "valX, testX, valy, testy = train_test_split(valX, valy, train_size=0.5, random_state=486)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "super-indian",
   "metadata": {},
   "source": [
    "# Train SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "relative-olympus",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC()"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "svc.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-there",
   "metadata": {},
   "source": [
    "## Evaluate SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "retired-voice",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7948497854077253, 0.7984822934232715, 0.8789218028348464)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(valy, svc.predict(valX)), accuracy_score(valy, svc.predict(valX)), roc_auc_score(valy, svc.decision_function(valX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "vanilla-hello",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7948497854077253"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(svc.predict(valX), valy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "focal-bridge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7984822934232715"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(svc.predict(valX), valy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-country",
   "metadata": {},
   "source": [
    "## Features with highest and lowest coefs\n",
    "\n",
    "It looks like most of the features with extreme coefficients are actually usernames. Let's try to filter those out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "duplicate-teddy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['hunterhayes', 'hamillhimself', 'jmpalmieri', 'schittscreek',\n",
       "       'alxthomp', 'maragay', 'doriskgoodwin', 'agbecerra', 'juliahamm',\n",
       "       'carole_king', 'lenses', 'marktakesphoto', 'advocate', 'telescope',\n",
       "       'keishabottoms', 'lawyerbobbauer', 'bfinamore', 'jacqehoward',\n",
       "       'remaining', 'adamwren', 'staircases', 'derricknaacp',\n",
       "       'lynnoberlander', 'beautifully', 'merrillbro', 'rahmemanuel',\n",
       "       'previously', 'ron_christie', 'lets', 'radhikajones', 'astro_cady',\n",
       "       'objets', 'gdebenedetti', 'sweater', 'erickmsanchez', 'texas',\n",
       "       'johndonvan', 'glorious', 'celinedion', 'bbheathertom',\n",
       "       'katedicamillo', 'ericswalwell', 'stained', 'identified',\n",
       "       'torontostar', 'superior', 'mrhollywoodmd', 'governor',\n",
       "       'ricktelesz', 'meganpormer'], dtype='<U28')"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.argsort(svc.coef_)[0, -50:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "cheap-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['christrapper', 'loganplaster', 'sarahnferris', 'gregstohr',\n",
       "       'chrishell7', 'andreayoungatl', 'nkechi_taifa', 'costareports',\n",
       "       'markherringva', 'ctvqp', 'blacksnob', 'kate_manne', 'senatorgill',\n",
       "       'crying', 'drmcclellan', 'henadoba', 'laurenzelt', 'repjoshg',\n",
       "       'mpinoe', 'rinsana', 'jamesfortexas', 'niknanos', 'lot',\n",
       "       'vladduthierscbs', 'mooch', 'rehang', 'docking', 'interplay',\n",
       "       'rozweston', 'susanlejeuneuk', 'mryangorman', 'ambermcreynolds',\n",
       "       'domingomorel', 'jordanwitzel', 'deanobeidallah', 'potential',\n",
       "       'hankazaria', 'declutter', 'juliaioffe', 'chrisdaleoxford',\n",
       "       'edyong209', 'secret', 'zekejmiller', 'bernadeansteptoe',\n",
       "       'haleyjoelleott', 'milnerhrich', 'rachaelcobb', 'blairunderwood',\n",
       "       'brought', 'spread'], dtype='<U28')"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.argsort(svc.coef_)[0, :50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "photographic-stanford",
   "metadata": {},
   "outputs": [],
   "source": [
    "at_re = re.compile(r\"@[\\w_]+\")\n",
    "def strip_ats(tweet):\n",
    "    return at_re.sub(\"\", tweet)\n",
    "\n",
    "hash_re = re.compile(r\"#\\w+\")\n",
    "def strip_hashtags(tweet):\n",
    "    return hash_re.sub(\"\", tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "southern-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(data.cleaned.apply(strip_ats).apply(strip_hashtags))\n",
    "y = data.rating > data.rating.median()\n",
    "\n",
    "trainX, valX, trainy, valy = train_test_split(X, y, train_size=0.8, random_state=486)\n",
    "valX, testX, valy, testy = train_test_split(valX, valy, train_size=0.5, random_state=486)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "cosmetic-thanksgiving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7857142857142857, 0.7875210792580101, 0.8712616317429982)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc.fit(trainX, trainy)\n",
    "f1_score(svc.predict(valX), valy), accuracy_score(svc.predict(valX), valy), roc_auc_score(valy, svc.decision_function(valX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "electric-operator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fiction', 'scented', 'congratulations', 'bipartisanship',\n",
       "       'celebrating', 'livable', 'fauci', 'telescope', 'sailing',\n",
       "       'filled', 'lover', 'bacon', 'schmancy', 'murals', 'chia', 'wutang',\n",
       "       'chord', 'sweater', 'advocate', 'wow', 'hunger', 'stained',\n",
       "       'forecast', 'inappropriate', 'china', 'clients', 'daggers',\n",
       "       'bamboo', 'brooklyn', 'staircases', 'nicest', 'innis', 'texas',\n",
       "       'labor', 'bartlett', 'felled', 'extremely', 'flawless',\n",
       "       'previously', 'beautifully', 'remaining', 'governor', 'hitting',\n",
       "       'glorious', 'arched', 'lets', 'lenses', 'superior', 'identified',\n",
       "       'objets'], dtype='<U19')"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.argsort(svc.coef_)[0, -50:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "cosmetic-industry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['sock', 'sort', 'scandal', 'interplay', 'crying', 'repositon',\n",
       "       'wants', 'clothes', 'shame', 'paneled', 'stage', 'readjust',\n",
       "       'alcohol', 'pussywillows', 'kerry', 'vaccinated', 'mooch',\n",
       "       'styling', 'lot', '19th', 'ching', 'folliage', 'aces', 'austere',\n",
       "       'invisible', 'nora', 'lose', 'lowet', 'docking', 'aspen',\n",
       "       'scoreboards', 'reduce', 'recompose', 'fail', 'scientific',\n",
       "       'narrow', 'dome', 'clearly', 'source', 'indirect', 'tissues',\n",
       "       'proliferating', 'mybe', 'tan', 'potential', 'spread', 'barely',\n",
       "       'candlesticks', 'recreation', 'happening'], dtype='<U19')"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorizer.get_feature_names())[np.argsort(svc.coef_)[0, :50]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-climb",
   "metadata": {},
   "source": [
    "# Train Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "provincial-observer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "timely-garbage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = RandomForestClassifier()\n",
    "rfc.fit(trainX, trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "played-exploration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7877145438121048, 0.8018549747048904, 0.887216174095056)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    f1_score(valy, rfc.predict(valX)),\n",
    "    accuracy_score(valy, rfc.predict(valX)),\n",
    "    roc_auc_score(valy, rfc.predict_proba(valX)[:,1])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-selling",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
